% rubber: set program xelatex

% The theme used for this presentation is matze's mtheme, which can be
% found at https://github.com/matze/mtheme

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THINGS TO TALK ABOUT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
% Question: Green's function is NOT unique, so can we really treat it as
%           THE response to a source?
%           - Green's function is unique, given specified BC/IC's
%           - So we could say it's the response to the source, under the
%             the imposed BC/IC's
%           - But does this weaken the interpretation of BC/IC's as sources?
%           - Not really: It's the homogeneous BC's that make the Green's function unique
%
%
% Direct solution
%   - Discontinuity condition
%
% Eigenvalue solution
%
% Boundary conditions
%   - Green's function not arbitrary! Depends on BC/IC's.
%   - Idea of replacing BC/IC's with equivalent sources (Morse and Feshback)
%   - Relation to equivalence principle?
%   - Can also just find any Green's and add homogeneous solutions
%   - Can also solve adjoint Green's function problem
%
% Interpreting the Green's function
%   - Space-time invariance
%   - Self-adjointness (IC problems are not self-adjoint!)
%   - Reciprocity (weird combination of invariance/self-adjointness?)
%   - Poles are eigenvalues
%
% Wave equation causality
%   - Causal Green's functions comes from initial conditions in time domain
%   - Equivalent to assuming small loss (a la Harrington)
%   - Can replace initial conditions with equivalent sources
%   - Fourier transform actually fails here!
% 
% Scattering
%   - Interesting approximation technique (Born): the field itself is the source
% Perturbation theory?
% Huygens principle and the propagator?
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newif\ifhandout
\newif\ifextended

\handoutfalse
%\handouttrue

\extendedfalse
\extendedtrue

\ifhandout
    \documentclass[12 pt, compress, handout, intlimits]{beamer}

    \setbeamertemplate{note page}[plain]

    \setbeameroption{show notes}% on second screen=bottom}
\else

    \documentclass[12 pt, compress, intlimits]{beamer}

\fi

\usetheme{m}

\usepackage{mymacros}
\usepackage[retainorgcmds]{IEEEtrantools}
\setlength{\IEEEnormaljot}{9pt}

\renewcommand{\d}{\operatorname{d}}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage[scale=2]{ccicons}
\usepackage{array}

\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{empheq}

\newcommand{\highlight}[1]{\colorbox{mLightBrown!65}{$\displaystyle{#1}$}}
\newcommand{\mygreenbox}[1]{\colorbox{mLightBrown!65}{\hspace{1em}#1\hspace{1em}}}
\newcommand*\widefbox[1]{\fbox{\hspace{1em}#1\hspace{1em}}}

%\usepackage{sourcesanspro}

\usepgfplotslibrary{dateplot}

%\usefonttheme[onlymath]{serif}
%\usepackage{eulervm}
%\usepackage{arevmath}
%\renewcommand{\vect}[1]{\vec{#1}}
\renewcommand{\L}{\mathcal{L}}

\useinnertheme{circles}

\setbeamercovered{transparent}

\title{Green's functions}
\subtitle{A short introduction}
\date{\today}
\author{Chris Deimert}
\institute{Department of Electrical and Computer Engineering, University of Calgary}


\begin{document}

\maketitle

\note{
    \begin{itemize}
    \item
        This is intended as a quick overview of Green's functions for electrical engineers.
    \item
        Green's functions are a huge subject: it's easy to get overwhelmed by calculation techniques. 
    \item
        Focus here will be on intuition/understanding and awareness of some key techniques.
    \item
        Lots of further reading provided at the end.
    \item
        Tip: read a lot of different references. Different authors take totally different approaches and it's interesting to see them all.
    \end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Outline}
    \tableofcontents
\end{frame}

\note{}

\section{Introduction}
\label{sec:introduction}

\note{
\begin{itemize}
\item
    Fortunately, the basic idea of Green's functions is really simple.
\item
    You've actually used them before!
\item
    What's far more interesting is how to calculate/interpret them.
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{What is a Green's function?}
    
    Linear equation to solve:
    \begin{align*}
        \L u(x) &= f(x)
    \end{align*}
    
    \pause

    Green's function is the \textbf{impulse response}:
    \begin{align*}
        \L G(x,x') &= \delta(x - x')
    \end{align*}

\end{frame}

\note{
\begin{itemize}
\item
    Most EM problems are described by linear (differential) equations with some source/driving function $ f(x) $.
\item
    The Green's function is the solution when the source $ f(x) $ is an impulse located at $ x' $.
\item
    Can think of it as a generalization of the impulse response from signal processing.
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Why is it useful?}
    
    \begin{align*}
        \delta(x - x') &\xrightarrow{\quad \L^{-1} \quad} G(x,x')
    \end{align*}
 
    \pause

    \begin{align*}
        f(x) = \int \delta(x - x') f(x') \d x \xrightarrow{\quad \L^{-1} \quad} \int G(x,x') f(x') \d x
    \end{align*}
  
    %Can find the solution directly for any $ f(x) $:
    %\begin{align*}
    %    u(x) &= \int G(x,x') f(x') \d x
    %\end{align*}
    %\begin{align*}
    %    \L u(x) &= \int \L G(x,x') f(x') \d x = \int \delta(x - x') f(x) \d x = f(x)
    %\end{align*}
    
\end{frame}

\note{
\begin{itemize}
\item
    Once we know the Green's function for a problem, we can find the solution for any source $ f(x) $.
\item
    Impulses $ \delta(x - x') $ produce a response $ G(x,x') $.
\item
    We can split the source $ f(x) $ up into a sum (integral) of impulses $ \delta(x - x') $.
\item
    Then the response to $ f(x) $ is just a weighted sum (integral) of impulse responses.
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Why is it useful?}

    \begin{align*}
        \L u(x) &= f(x)
    \end{align*}
    \begin{align*}
        \L G(x,x') &= \delta(x - x')
    \end{align*}
    \begin{empheq}[box=\widefbox]{align*}
        u(x) = \int G(x,x') f(x') \d x
    \end{empheq}

\end{frame}

\note{
\begin{itemize}
\item
    Once we know the Green's function, we have an explicit formula for the solution $ u(x) $ for any source function $ f(x) $.
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Familiar Green's functions}

    Impulse response of a LTI system:
    \begin{align*}
        y(t) &= \int_{-\infty}^{\infty} x(t') \alert{h(t - t')} \d t'
    \end{align*}

    \pause
    E.g., for an RL-circuit:
    \begin{align*}
        G(t,t') &= h(t - t') = u(t - t') e^{-\alpha (t - t')}
    \end{align*}
    
\end{frame}

\note{
\begin{itemize}
\item
    In electrical engineering, we've seen Green's functions before.
\item
    Impulse response $ h(t - t') $ from linear system theory is an example of a Green's function.
    \begin{align*}
        G(t,t') & = h(t - t')
    \end{align*}
\item
    Usually find $ h(t - t') $ using Fourier transform of the transfer function.
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Familiar Green's functions}

    Poisson's equation:
    \begin{align*}
        \nabla^2 V(\vect{r}) &= - \frac{\rho(\vect{r})}{\epsilon_0}
    \end{align*}
    \begin{align*}
        V(\vect{r}) &= \iiint \alert{\frac{1}{4 \pi \epsilon_0 \left| \vect{r} - \vect{r}' \right|^2}} \rho(\vect{r}') \d^3 \vect{r}'
    \end{align*}
\end{frame}

\note{
    \begin{itemize}
    \item
        Green's function for Poisson's equation is
        \begin{align*}
            G(\vect{r}, \vect{r}') &= \frac{1}{4 \pi \epsilon_0 \left| \vect{r} - \vect{r}' \right|^2}
        \end{align*}
    \end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Familiar Green's functions}
    
    Helmholtz equation:
    \begin{align*}
        \left( \nabla^2 + k^2 \right) A_z(\vect{r}) &= -J_z(\vect{r})
    \end{align*}
    \begin{align*}
        A_z(\vect{r}) &= \iiint \alert{\frac{e^{-jk \left| \vect{r} - \vect{r}' \right|}}{4 \pi \left| \vect{r} - \vect{r}' \right|}} J_z\left( \vect{r}' \right) \d^3 \vect{r}'
    \end{align*}
\end{frame}

\note{
    \begin{itemize}
    \item
        Green's function for the Helmholtz equation is
        \begin{align*}
            G(\vect{r}, \vect{r}') &= \frac{e^{-jk \left| \vect{r} - \vect{r}' \right|}}{4 \pi \left| \vect{r} - \vect{r}' \right|}
        \end{align*}
    \end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Familiar Green's functions}
    
    Our goal:
    \begin{itemize}
    \item
        Derive these expressions.
    \item
        Generalize to other problems and boundary conditions.
    \end{itemize}
    
\end{frame}

\note{
}

\section{Generalized functions}
\label{sec:generalized_functions}

\note{
    \begin{itemize}
    \item
        Delta functions play a key role in Green's functions (and electrical engineering in general), but tend to lead to hand-waving.
    \item
        Worth seeing how they can be rigorously defined before moving on.
    \item
        Machinery for this is Schwartz's theory of distributions (generalized functions).
    \item
        See Folland (1992), \emph{Fourier analysis and its applications}, Chapter 9 for more.
    \end{itemize}
    
}

\begin{frame}[fragile]
    \frametitle{Typical delta function definition}
    
    Typical ``definition'' of $ \delta(x - x_0) $:
    \begin{align*}
        \delta(x-x_0) &= 0 \quad \text{for} \quad x \neq x_0
    \end{align*}
    \begin{align*}
        \int_{-\infty}^{\infty} \delta(x-x_0) &= 1
    \end{align*}
    
\end{frame}

\note{
\begin{itemize}
\item
    Often see definitions like this one.
\item
    Often said to imply that $ \delta(x - x_0) = \infty $ at $ x = x_0 $.
\item
    Might be okay intuitively, but very imprecise mathematically.
\item
    There is no true function which satisfies both of these requirements!
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Generalized functions}
    
    $ f(x) $ defines a linear operator $ \phi(x) $ via
    \begin{align*}
        f[\phi] &= \int_{-\infty}^{\infty} f(x) \phi(x) \d x
    \end{align*}
    
\end{frame}

\note{
\begin{itemize}
\item
    Let's see if we can generalize the idea of a ``function'' so that it includes delta functions.
\item
    Given a function $ f(x) $, we can use it to define a linear operator (a functional, to be exact) on other functions $ \phi(x) $.
\item
    $ f[\cdot] $ is a linear operator. It takes a function $ \phi(x) $ and returns the number
    \begin{align*}
        f[\phi] &= \int_{-\infty}^{\infty} f(x) \phi(x) \d x
    \end{align*}
\item
    If we ensure that $ \phi(x) $ is very well-behaved, then every function $ f(x) $ defines an operator in this way.
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Generalized functions}

    If we have $ f[\phi] $, but no $ f(x) $, then $ f $ is a generalized function.
    
    \textbf{Symbolically}, we write
    \begin{align*}
        f[\phi] &\stackrel{s}{=} \int_{-\infty}^{\infty} f(x) \phi(x) \d x
    \end{align*}
    
\end{frame}

\note{
    \begin{itemize}
    \item
        It's possible to have an operator $ f[\phi] $, but we can't find an $ f(x) $ to implement it via an integral.
    \item
        Then $ f(x) $ is a generalized function. It is not a function in its own right, but it is defined purely by its action on other functions $ f[\phi] $.
    \item
        We still symbolically write
        \begin{align*}
            f[\phi] &\stackrel{s}{=} \int_{-\infty}^{\infty} f(x) \phi(x) \d x
        \end{align*}
        but this just suggestive notation. 
        It is not actually an integral unless $ f(x) $ is a ``proper'' function!
    \end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Defining the delta function}

    $ \delta(x-x_0) $ is a generalized function defined by the sifting property
    \begin{align*}
        \delta_{x_0}[\phi] &= \phi(x_0) \stackrel{s}{=} \int_{-\infty}^{\infty} \delta(x - x_0) \phi(x) \d x
    \end{align*}
    
\end{frame}

\note{
\begin{itemize}
\item
    We can define a simple linear operator via the sifting property $ \delta_{x_0}[\phi] = \phi(x_0) $.
\item
    There is no actual function $ \delta(x - x_0) $ which gives
    \begin{align*}
        \int_{-\infty}^{\infty} \delta(x - x_0) \phi(x) \d x &= \phi(x_0)
    \end{align*}
    so $ \delta(x - x_0) $ is a generalized function and the above integral is purely symbolic.
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Delta function derivatives}
    
    We can define derivatives too:
    \begin{align*}
        \delta^{(n)}_{x_0}[\phi] &= (-1)^n \phi^{(n)}(x_0) \stackrel{s}{=} \int_{-\infty}^{\infty} \delta^{(n)}(x - x_0) \phi(x) \d x
    \end{align*}

\end{frame}

\note{
\begin{itemize}
\item
    Generalized function theory lets us make sense of the derivatives of the delta function too.
\item
    $ \delta_{x_0}^{(n)} $ is just an operator that picks out the value of the $ n $th derivative of $ \phi(x) $ at the point $ x_0 $.
\end{itemize}
}

\ifextended
\begin{frame}[fragile]
    \frametitle{Delta function limits}
    
    \begin{align*}
        \lim_{\epsilon \to 0} f_\epsilon(x) &= \delta(x)
    \end{align*}
    if and only if
    \begin{align*}
        \lim_{\epsilon \to 0} f_\epsilon[\phi] = \lim_{\epsilon \to 0} \int_{-\infty}^{\infty} f_\epsilon(x) \phi(x) \d x &= \phi(0)
    \end{align*}
    
\end{frame}

\note{
\begin{itemize}
\item
    Often useful to show that some set of actual functions $ f_\epsilon(x) $ ``approach'' the delta function in a limit.
\item
    To do this, we need to show that the sifting property is obeyed in the limit.
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Delta function limits}
    Limit of Gaussian functions:
    \begin{align*}
        \delta(x) &= \lim_{\epsilon \to 0} \frac{1}{\sqrt{2 \pi} \epsilon} e^{- x^2/ 2 \epsilon^2}
    \end{align*}
    Limit of Lorentzian functions:
    \begin{align*}
        \delta(x) &= \lim_{\epsilon \to 0} \frac{1}{\pi} \frac{\epsilon}{t^2 + \epsilon^2}
    \end{align*}
\end{frame}

\note{
\begin{itemize}
\item
    Two examples of delta function limits.
\item
    Confirms our intuition of the delta function as a limit of sharply-peaked functions.
\item
    In fact, basically any limit of sharply-peaked functions of area 1 will work: see Folland (Theorem 9.2).
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{Delta function limits}
    A more interesting example:
    \begin{align*}
        \frac{1}{2 \pi} \int_{-\infty}^{\infty} e^{j x t} \d t &= \delta(x)
    \end{align*}
    because
    \begin{align*}
        \lim_{\epsilon \to 0} \frac{1}{2 \pi} \int_{-\infty}^{\infty} e^{-\epsilon^2 t^2} e^{j x t} \d t = \delta(x)
    \end{align*}

\end{frame}

\note{
    \begin{itemize}
    \item
        Example of a common, but unintuitive expression for the Delta function.
    \item
        Can show that it's true by expressing it as a delta function limit. (If you want to go through it, use Theorem 9.2 from Folland.)
    \end{itemize}
    
}
\fi

\begin{frame}[fragile]
    \frametitle{What does this mean for Green's functions?}
    
    \begin{align*}
        \L G(x, x') &= \delta(x - x')
    \end{align*}
    actually means
    \begin{align*}
        \left( \L G \right)[\phi]  &= \phi(x') \stackrel{s}{=} \int_{-\infty}^\infty \left( \L G(x, x')\right) \phi(x) \d x
    \end{align*}
\end{frame}

\note{
\begin{itemize}
\item
    Technically, the Green's function is a generalized function such that $ \L G $ is the delta function (it has the sifting property).
\item
    In practise, we'll keep using the less-precise way; just remember that there is a more correct way.
\end{itemize}

}

\begin{frame}[fragile]
    \frametitle{Takeaway}
    
    \begin{center}
        If in doubt, think of $ \delta(x - x_0) $ as an operator, not a function!
    \end{center}

\end{frame}

\note{
\begin{itemize}
\item
    In practise, thinking of $ \delta(x - x_0) $ as a function is usually fine.
    (We'll even do that for the rest of this presentation.)
\item
    But if anything starts to seem fishy, it's good to remember that $ \delta(x - x_0) $ is actually an operator, and not a function.
\end{itemize}
    
}

\section{Direct solution}
\label{sec:direct_solution}

\note{
    \begin{itemize}
    \item
        Back to Green's functions!
    \end{itemize}
}

\begin{frame}[fragile]
    \frametitle{A simple example}

    Original problem:
    \begin{align*}
        \frac{\d^2 u(x)}{\d x^2} - k^2 u(x) &= f(x)
    \end{align*}
    
    Green's function problem:
    \begin{align*}
        \frac{\d^2 G(x, x')}{\d x^2} - k^2 G(x,x') &= \delta(x - x')
    \end{align*}
    

\end{frame}

\note{
\begin{itemize}
\item
    Let's look at a simple example now.
\item
    This problem is similar to a simple harmonic oscillator, but the negative sign means we expect lossy behaviour rather than oscillation.
\item
    We won't worry much about boundary conditions yet, we'll just look for solutions that don't blow up at $ x = \pm \infty $.
\item
    If we can find the Green's function, then we can find the solution to the original problem.
\item
    But the Green's function problem looks pretty hard. The point of this example is to demonstrate that we can actually solve it.
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{A simple example}

    For $ x \neq x' $
    \begin{align*}
        \frac{\d^2 G(x, x')}{\d x^2} - k^2 G(x,x') &= 0
    \end{align*}
    
    \pause
    So we have
    \begin{align*}
        G(x,x') &= 
        \begin{cases} 
            A e^{+k (x - x')} & \text{for } x < x'
            \\
            B e^{-k (x - x')} & \text{for } x > x'
        \end{cases}
    \end{align*}
    
    
\end{frame}

\note{
    \begin{itemize}
    \item
        Key thing to notice is that the source is concentrated at $ x = x' $.
    \item
        So for $ x > x' $ and $ x < x' $, we expect the solutions to look like those of the source-free equation.
    \item
        To keep the solutions finite, we expect exponential growth before $ x = x' $ and exponential decay afterward.
    \item
        Now, how do we find the constants $ A $ and $ B $?
    \end{itemize}
}

\begin{frame}[fragile]
    \frametitle{A simple example}

    \begin{align*}
        \frac{\d^2 G(x,x')}{\d x^2} - k^2 G(x,x') &= \delta(x - x')
    \end{align*}

    Continuity of the Green's function:
    \begin{align*}
        \lim_{\epsilon \to 0} \left[ G(x'+\epsilon, x') - G(x' - \epsilon, x') \right] = 0
    \end{align*}

\end{frame}

\note{
\begin{itemize}
\item
    How continuous do we expect our Green's function to be?
\item
    If $ G(x,x') $ is discontinuous (like a step function), then $ \d G / \d x $ will behave like a delta function and $ \d^2 G / \d x^2 $ will behave like a delta function derivative. No good!
\item
    So we expect $ G(x,x') $ to be continuous.
\item
    That gives us one condition we can use to find $ A $ and $ B $. (In fact, it tells us that $ A = B $.)
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{A simple example}
 
    \begin{align*}
        \alt<2->{\int_{x'-\epsilon}^{x'+\epsilon} \left[ \frac{\d^2 G(x, x')}{\d x^2} - k^2 G(x,x') \right] \d x &= \int_{x'-\epsilon}^{x'+\epsilon} \delta(x - x') \d x}{\frac{\d^2 G(x, x')}{\d x^2} - k^2 G(x,x') = \delta(x - x')}
    \end{align*}

    Discontinuity condition:
    \begin{align*}
        \lim_{\epsilon \to 0} \left[ \left. \frac{\d G}{\d x}\right|_{x = x' + \epsilon} - \left. \frac{\d G}{\d x} \right|_{x = x' - \epsilon} \right] &= 1
    \end{align*}
    

\end{frame}

\note{
    \begin{itemize}
    \item
        But what if the derivative $ \d G / \d x $ is discontinuous?
    \item
        Then $ \d^2 G / \d x^2 $ is like a delta function.
        But that's fine, because we have a delta function on the right hand side too.
    \item
        We can find exactly how discontinuous the derivative is by integrating over a small interval around $ x' $.
    \item
        In the limit of $ \epsilon \to 0 $, the second integral vanishes because $ G(x,x') $ is continuous.
    \item
        But, we expect $ \d G / \d x $ to be discontinous. 
    \item
        Using fundamental theorem of calculus, we get at a \emph{discontinuity condition for the derivative.} (Key idea for the direct solution method!)
    \end{itemize}
}

\begin{frame}[fragile]
    \frametitle{A simple example}

    \begin{align*}
        G(x,x') &= 
        \begin{cases} 
            A e^{+k (x - x')} & \text{for } x < x'
            \\
            B e^{-k (x - x')} & \text{for } x > x'
        \end{cases}
    \end{align*}
    
    Continuity of $ G $:
    \begin{align*}
        A &= B
    \end{align*}

    Discontinuity of $ \frac{\d G}{\d x} $:
    \begin{align*}
        k A + k B &= 1
    \end{align*}
    
\end{frame}

\note{
\begin{itemize}
\item
    Applying our two conditions, we can solve for $ A $ and $ B $.
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{A simple example}
    At last, our Green's function is
    \begin{align*}
        G(x,x') &= 
        \begin{dcases} 
            \dfrac{e^{+k (x - x')}}{2k} & \text{for } x < x'
            \\
            \dfrac{e^{-k (x - x')}}{2k} & \text{for } x > x'
        \end{dcases}
    \end{align*}
    or, more compactly
    \begin{empheq}[box=\widefbox]{align*}
        G(x, x') = \frac{e^{k |x - x'|}}{2 k}
    \end{empheq}
    

\end{frame}

\note{
}

\begin{frame}[fragile]
    \frametitle{A simple example}
    Solution:
    \begin{align*}
        u(x) &= \int_{-\infty}^{\infty} f(x') \frac{e^{k|x - x'|}}{2k} \d x'
    \end{align*}
    
\end{frame}

\note{
\begin{itemize}
\item
    Now that we have the Green's function, we can construct the solution to our original problem for any forcing function $ f(t) $.
\end{itemize}
}

\begin{frame}[fragile]
    \frametitle{General approach}
    Properties of $ G(x,x') $:
    \begin{itemize}
    \item
        Looks like the sourceless solution except at $ x = x' $.
    \item
        Function is continuous at $ x = x' $.
    \item
        Derivative is discontinuous at $ x = x' $.
    \end{itemize}
    
\end{frame}

\note{
    \begin{itemize}
    \item
        Listed are the key things to note from that example.
    \item
        This approach works quite well for solving 1D Green's function problems.
    \end{itemize}
}

\section{Boundary conditions}
\label{sec:boundary_conditions}

\note{
}

\section{Spectral methods}
\label{sec:spectral_methods}

\note{}

\section{3D problems}
\label{sec:3d_problems}

\note{}

\section{Properties of the Green's function}
\label{sec:properties_of_the_green_s_function}

\note{}

\section{Advanced topics}
\label{sec:advanced_topics}

\note{}


\begin{frame}[fragile]
    \frametitle{Introductory resources}
    Balanis (2012), \emph{Advanced engineering electromagnetics}. 
    Less rigorous, but good for getting the key ideas.

    Folland (1992), \emph{Fourier analysis and its applications}. 
    Chapter on generalized functions is particularly nice.

    Dudley (1994), \emph{Mathematical foundations for electromagnetic theory}.
    Great introduction to 1D Green's functions: deals with subtleties that others ignore.

    Byron and Fuller (1992), \emph{Mathematics of classical and quantum physics}.
    Interesting alternative approach.
    
\end{frame}

\note{}

\begin{frame}[fragile]
    \frametitle{Advanced resources}
    Collin (1990), \emph{Field theory of guided waves}. 
    Huge chapter on Green's functions. Emphasis on dyadics.

    Morse and Feshback, \emph{Methods of theoretical physics}.
    Another big, detailed reference. Emphasis on theory and insights.

    Warnick (1996), ``Electromagnetic Green functions using differential forms.''
    For the differential forms inclined.

\end{frame}    

\note{}

\end{document}
